{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw7eyJsuMsxH"
      },
      "source": [
        "## ğŸ” GEPA: ìœ ì „ ì§„í™” í”„ë¡¬í”„íŠ¸ ì•„í‚¤í…ì²˜\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ LLM í”¼ë°± ë£¨í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ì§„í™”ì‹œí‚¤ëŠ” ìë™ í”„ë¡¬í”„íŠ¸ ìµœì í™” í”„ë ˆì„ì›Œí¬ì¸ **GEPA**ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. **OpenAI GPT ëª¨ë¸**ê³¼ **Google Gemini ëª¨ë¸**ì„ ëª¨ë‘ ì§€ì›í•˜ì—¬ ìœ ì—°í•œ êµ¬ì„±ê³¼ ë¹ ë¥¸ ì‹¤í—˜ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "-----\n",
        "\n",
        "### ğŸš€ ì£¼ìš” ê¸°ëŠ¥\n",
        "\n",
        "  * ì¼ë ¨ì˜ í›ˆë ¨ ì‘ì—…ì— ëŒ€í•´ ì‹œë“œ(seed) í”„ë¡¬í”„íŠ¸ë¥¼ **í‰ê°€í•©ë‹ˆë‹¤**.\n",
        "  * ì‚¬ìš©ì ì§€ì • í‰ê°€ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ í’ˆì§ˆì˜ **ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤**.\n",
        "  * ê°•ë ¥í•œ 'ë¦¬í”Œë ‰í„°(reflector)' ëª¨ë¸(ì˜ˆ: Gemini 2.5 Pro)ì„ ì‚¬ìš©í•˜ì—¬ **í”„ë¡¬í”„íŠ¸ë¥¼ ë³€í˜•í•©ë‹ˆë‹¤**.\n",
        "  * ì—¬ëŸ¬ ì‘ì—…ì— ê±¸ì³ íŒŒë ˆí†  ìµœì í™”(Pareto optimization)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤**.\n",
        "  * ì‹¤í–‰ ì¤‘ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ í”„ë¡¬í”„íŠ¸ë¥¼ **ì¶”ì í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤**.\n",
        "\n",
        "-----\n",
        "\n",
        "### ğŸ”§ í•„ìš”í•œ ì„¤ì •\n",
        "\n",
        "ì‹¤í–‰í•˜ê¸° ì „ì— ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:\n",
        "\n",
        "âœ… API í‚¤ë¥¼ ì €ì¥í•˜ì„¸ìš”:\n",
        "\n",
        "\n",
        "\n",
        "âœ… ë‹¤ìŒì„ ì„¤ì •í•˜ì„¸ìš”:\n",
        "\n",
        "  * `OPENAI_MODEL_NAME` (OpenAI GPT ì‚¬ìš© ì‹œ) **ë˜ëŠ”**\n",
        "  * `TARGET_MODEL_NAME` ë° `REFLECTOR_MODEL_NAME` (Gemini ì‚¬ìš© ì‹œ)\n",
        "\n",
        "âœ… ë‹¤ìŒì„ ì œê³µí•˜ì„¸ìš”:\n",
        "\n",
        "  * ìµœì í™”í•  `SEED_PROMPT`.\n",
        "  * ê°ê° ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” `TRAINING_DATA` í•­ëª© ëª©ë¡:\n",
        "      * `input`: ì…ë ¥ í…ìŠ¤íŠ¸.\n",
        "      * `expected_keywords`: ì¢‹ì€ ì¶œë ¥ì— í¬í•¨ë˜ì–´ì•¼ í•  í‚¤ì›Œë“œ ëª©ë¡.\n",
        "\n",
        "âœ… `BUDGET`(ëª¨ë¸ì„ ì¿¼ë¦¬í•  ìˆ˜ ìˆëŠ” íšŸìˆ˜)ì„ ì •ì˜í•˜ì„¸ìš”.\n",
        "\n",
        "-----\n",
        "\n",
        "### ğŸ§  ì‚¬ìš© ì˜ˆì‹œ\n",
        "\n",
        "ì—¬ëŸ¬ë¶„ì˜ ì‹œë“œ í”„ë¡¬í”„íŠ¸ê°€ ëª¨ë¸ì—ê²Œ í…ìŠ¤íŠ¸ ìš”ì•½ì„ ìš”ì²­í•œë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤. GEPAëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
        "\n",
        "1.  ì˜ˆì‹œ ì…ë ¥ì— ëŒ€í•´ í•´ë‹¹ í”„ë¡¬í”„íŠ¸ê°€ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰ë˜ëŠ”ì§€ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.\n",
        "2.  ì„±ëŠ¥ì„ ê¸°ë°˜ìœ¼ë¡œ Geminiì—ê²Œ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤.\n",
        "3.  ì—¬ëŸ¬ ì„¸ëŒ€ì— ê±¸ì³ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ì§„í™”ì‹œí‚µë‹ˆë‹¤.\n",
        "4.  ë§ˆì§€ë§‰ì— **ê°€ì¥ ì˜ ì§„í™”ëœ í”„ë¡¬í”„íŠ¸**ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "-----\n",
        "\n",
        "### ğŸ“¦ í¬í•¨ëœ êµ¬í˜„ ì‚¬í•­\n",
        "\n",
        "  * âœ… `openai` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•œ `OpenAI API` ì§€ì›\n",
        "  * âœ… `google-generativeai`ë¥¼ í†µí•œ `Google Generative AI` ì§€ì›\n",
        "  * âœ… ë°˜ì„±ì  í”¼ë“œë°± ë£¨í”„ (Reflective feedback loop)\n",
        "  * âœ… íŒŒë ˆí†  ê¸°ë°˜ í›„ë³´ ì„ íƒ\n",
        "  * âœ… ì˜ˆì‹œ í‰ê°€ í•¨ìˆ˜ (í‚¤ì›Œë“œ ë§¤ì¹­ ë°©ì‹ â€” ì‰½ê²Œ ë§ì¶¤ ì„¤ì • ê°€ëŠ¥)\n",
        "\n",
        "-----\n",
        "\n",
        "### ğŸ§ª ì¶”ì²œ ëŒ€ìƒ\n",
        "\n",
        "  * í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ìë™í™”ë¥¼ ì—°êµ¬í•˜ëŠ” ì—°êµ¬ì›\n",
        "  * **LLM APIìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìµœì í™”**í•˜ë ¤ëŠ” íŒ€\n",
        "  * **í”¼ë“œë°±ì„ í†µí•œ LLM ìê°€ ê°œì„ ** êµìœ¡ìš© ë°ëª¨\n",
        "\n",
        "-----\n",
        "\n",
        "### ğŸ“ˆ ì¶”ì²œ ëª¨ë¸\n",
        "\n",
        "  * OpenAI: `gpt-4o`\n",
        "  * Google: `gemini-2.5-flash`, `gemini-2.5-pro`\n",
        "\n",
        "> âš ï¸ OpenAI ë° Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ **API ì•¡ì„¸ìŠ¤ ê¶Œí•œ**ì´ í•„ìš”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ì´ ì½”ë“œëŠ” **GEPA(Genetic-Evolutionary Prompt Architecture)** ë¼ëŠ” í”„ë¡¬í”„íŠ¸ ìµœì í™” í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤. ì‰½ê²Œ ë§í•´, **AIê°€ ìŠ¤ìŠ¤ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³ , ì‹¤íŒ¨ë¡œë¶€í„° í•™ìŠµí•˜ì—¬ ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” 'í”„ë¡¬í”„íŠ¸ ìë™ íŠœë‹ ì‹œìŠ¤í…œ'**ì…ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "### ## í•µì‹¬ êµ¬ì„± ìš”ì†Œì™€ ì—­í• \n",
        "\n",
        "ì´ ì‹œìŠ¤í…œì€ ì—­í• ì´ ë‹¤ë¥¸ ë‘ ê°œì˜ AI ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "1.  **ìµœì í™” ëŒ€ìƒ ëª¨ë¸ (Target Model): `gpt-4o-mini`**\n",
        "    * ì´ ëª¨ë¸ì´ ë°”ë¡œ ìš°ë¦¬ê°€ **ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ì‹¶ì€ 'ì„ ìˆ˜'**ì…ë‹ˆë‹¤.\n",
        "    * í•´ì»¤í†¤ì˜ ê³¼ì œì¸ 'ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜'ë¥¼ ì‹¤ì œë¡œ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "    * ìš°ë¦¬ì˜ ëª©í‘œëŠ” ì´ `gpt-4o-mini`ê°€ ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‚´ë„ë¡ ë§Œë“œëŠ” ìµœì ì˜ ì§€ì‹œì„œ(ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)ë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "2.  **í”„ë¡¬í”„íŠ¸ ê°œì„  ëª¨ë¸ (Reflector Model): `gemini-2.5-pro`**\n",
        "    * ì´ ëª¨ë¸ì€ ì‹œìŠ¤í…œ ì „ì²´ì˜ **'ë‘ë‡Œ'ì´ì 'ì½”ì¹˜'** ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "    * `gpt-4o-mini`ê°€ íŠ¹ì • í”„ë¡¬í”„íŠ¸ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í–ˆì„ ë•Œì˜ ì„±ê³µ ë˜ëŠ” ì‹¤íŒ¨ ê²°ê³¼ë¥¼ ë³´ê³ , **\"ì™œ ì‹¤íŒ¨í–ˆì„ê¹Œ?\"** ë˜ëŠ” **\"ì–´ë–»ê²Œ í•˜ë©´ ë” ì˜í•  ìˆ˜ ìˆì„ê¹Œ?\"**ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\n",
        "    * ê·¸ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ë” ë‚˜ì€ ë²„ì „ì˜ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì œì•ˆ(ìƒì„±)í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ìƒ ëª¨ë¸ë³´ë‹¤ ë” í¬ê³  ê°•ë ¥í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "### ## ìµœì í™” ê³¼ì • (ìë™í™” ë£¨í”„)\n",
        "\n",
        "ì½”ë“œëŠ” `BUDGET`(ì˜ˆì‚°)ì´ ì†Œì§„ë  ë•Œê¹Œì§€ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ìë™ìœ¼ë¡œ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "* **1ë‹¨ê³„: ì´ˆê¸° í‰ê°€ (Initial Evaluation)**\n",
        "    1.  ë¨¼ì €, ì‚¬ëŒì´ ì‘ì„±í•œ `SEED_PROMPT`(ì´ˆê¸° í”„ë¡¬í”„íŠ¸)ë¥¼ `gpt-4o-mini`ì—ê²Œ ì¤ë‹ˆë‹¤.\n",
        "    2.  CSV íŒŒì¼ì—ì„œ ì½ì–´ì˜¨ ëª¨ë“  `TRAINING_DATA`(í›ˆë ¨ ë°ì´í„°)ì— ëŒ€í•´ ì´ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚µë‹ˆë‹¤.\n",
        "    3.  `evaluation_and_feedback_function`(í‰ê°€ í•¨ìˆ˜)ê°€ ê° ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ì±„ì í•˜ì—¬ ì´ˆê¸° í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , ì´ í”„ë¡¬í”„íŠ¸ë¥¼ 'í›„ë³´ 1ë²ˆ'ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "* **2ë‹¨ê³„: 'ë°˜ì„±'ì„ í†µí•œ ë¶„ì„ (Reflection)**\n",
        "    1.  í˜„ì¬ê¹Œì§€ ë§Œë“¤ì–´ì§„ í”„ë¡¬í”„íŠ¸ í›„ë³´ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
        "    2.  í›ˆë ¨ ë°ì´í„° ì¤‘ ë¬´ì‘ìœ„ë¡œ í•˜ë‚˜ë¥¼ ë½‘ì•„ `gpt-4o-mini`ì—ê²Œ ë‹¤ì‹œ ì‘ì—…ì„ ì‹œí‚µë‹ˆë‹¤.\n",
        "    3.  í‰ê°€ í•¨ìˆ˜ê°€ ê²°ê³¼ë¥¼ ì±„ì í•˜ê³ , \"ì‹¤íŒ¨: ì˜ˆìƒ ê°’ì€ '1'ì´ì—ˆì§€ë§Œ, ê²°ê³¼ëŠ” '0'ì´ì—ˆìŠµë‹ˆë‹¤.\"ì™€ ê°™ì€ ê°„ë‹¨í•œ í”¼ë“œë°±ì„ ë§Œë“­ë‹ˆë‹¤.\n",
        "    4.  ì´ **í”¼ë“œë°±, ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸, ì…ë ¥ ë°ì´í„°, ê·¸ë¦¬ê³  ëª¨ë¸ì˜ ì˜ëª»ëœ ì¶œë ¥**ì„ ëª¨ë‘ **`gemini-2.5-pro`(ì½”ì¹˜)**ì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "* **3ë‹¨ê³„: ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ìƒì„± (Mutation)**\n",
        "    1.  `gemini-2.5-pro`ëŠ” ì „ë‹¬ë°›ì€ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì˜ ë¬¸ì œì ì„ í•´ê²°í•˜ê³ , ê¸¸ì´ ì ìˆ˜ê¹Œì§€ ê³ ë ¤í•˜ì—¬ ë” ê°„ê²°í•˜ê³  íš¨ìœ¨ì ì¸ **ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "* **4ë‹¨ê³„: ìƒˆ í›„ë³´ í‰ê°€ ë° ì„ íƒ (Evaluation & Selection)**\n",
        "    1.  ìƒˆë¡­ê²Œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì‹œ ëª¨ë“  `TRAINING_DATA`ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸í•˜ì—¬ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "    2.  ì´ ì ìˆ˜ê°€ í˜„ì¬ê¹Œì§€ì˜ ìµœê³  ì ìˆ˜ë³´ë‹¤ ë†’ê±°ë‚˜ ê°™ìœ¼ë©´, ìƒˆë¡œìš´ 'í›„ë³´'ë¡œ ì±„íƒí•˜ì—¬ ë‹¤ìŒ ì‚¬ì´í´ì— ì‚¬ìš©ë  ìˆ˜ ìˆë„ë¡ ì €ì¥í•©ë‹ˆë‹¤. ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ íê¸°í•©ë‹ˆë‹¤.\n",
        "\n",
        "* **5ë‹¨ê³„: ë°˜ë³µ**\n",
        "    1.  ì •í•´ì§„ `BUDGET` íšŸìˆ˜ë§Œí¼ 2~4ë‹¨ê³„ë¥¼ ê³„ì† ë°˜ë³µí•©ë‹ˆë‹¤.\n",
        "    2.  ë£¨í”„ê°€ ëª¨ë‘ ëë‚˜ë©´, ê·¸ë™ì•ˆ ë§Œë“¤ì–´ì§„ ëª¨ë“  í›„ë³´ í”„ë¡¬í”„íŠ¸ ì¤‘ **ê°€ì¥ ë†’ì€ í‰ê·  ì ìˆ˜ë¥¼ ê¸°ë¡í•œ ìµœì¢… í”„ë¡¬í”„íŠ¸**ë¥¼ í™”ë©´ì— ì¶œë ¥í•´ ì¤ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "### ## ë¹„ìœ í•˜ìë©´...\n",
        "\n",
        "ì´ ê³¼ì •ì€ ë§ˆì¹˜ **'í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì¸ íŠ¸ë ˆì´ë„ˆ'**ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "* **ì„ ìˆ˜ (`gpt-4o-mini`)**ê°€ íŠ¹ì • ì§€ì‹œì„œ(í”„ë¡¬í”„íŠ¸)ë¥¼ ë³´ê³  í›ˆë ¨(ë‰´ìŠ¤ ë¶„ë¥˜)ì„ í•©ë‹ˆë‹¤.\n",
        "* **ì½”ì¹˜ (`gemini-2.5-pro`)**ê°€ ì„ ìˆ˜ì˜ í›ˆë ¨ ëª¨ìŠµì„ ë¹„ë””ì˜¤ë¡œ ë¶„ì„í•˜ì—¬ \"ì´ë²ˆì—” ì´ ë¶€ë¶„ì´ ë¬¸ì œì˜€ìœ¼ë‹ˆ, ë‹¤ìŒì—” ì´ë ‡ê²Œ í•´ë³´ì\"ë¼ê³  ë” ì¢‹ê³  ê°„ê²°í•œ ì§€ì‹œì„œë¥¼ ìƒˆë¡œ ì¨ì¤ë‹ˆë‹¤.\n",
        "* ì„ ìˆ˜ëŠ” ìƒˆë¡œìš´ ì§€ì‹œì„œë¡œ ë” ë‚˜ì€ ì„±ê³¼ë¥¼ ë‚´ê³ , ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ì—¬ ìµœê³ ì˜ ê¸°ë¡ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "nb94SyV0Lds8",
        "outputId": "c4687da9-b827-4e0e-eed5-5645751dee53"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 277\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mì‹¤í–‰ ì¤‘ ë³µêµ¬í•  ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ],
      "source": [
        "# --- 1. ì„¤ì¹˜ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import openai\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# --- í—¬í¼ í•¨ìˆ˜ ---\n",
        "\n",
        "def log_message(message, type='info'):\n",
        "    \"\"\"íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ë¡œê·¸ ë©”ì‹œì§€ í˜•ì‹ì„ ì§€ì •í•˜ëŠ” í—¬í¼ í•¨ìˆ˜.\"\"\"\n",
        "    timestamp = time.strftime(\"%H:%M:%S\")\n",
        "    if type == 'success':\n",
        "        return f\"[{timestamp}] âœ… ì„±ê³µ: {message}\"\n",
        "    if type == 'fail':\n",
        "        return f\"[{timestamp}] âŒ ì‹¤íŒ¨: {message}\"\n",
        "    if type == 'best':\n",
        "        return f\"[{timestamp}] â­ ìµœê³ : {message}\"\n",
        "    return f\"[{timestamp}] â„¹ï¸ ì •ë³´: {message}\"\n",
        "\n",
        "# --- GEPA í•µì‹¬ í•¨ìˆ˜ ---\n",
        "\n",
        "def run_openai_rollout(client: openai.Client, model_id: str, prompt: str, input_text: str) -> str:\n",
        "    \"\"\"\n",
        "    ëŒ€ìƒ ëª¨ë¸(gpt-4o-mini)ì— ëŒ€í•´ OpenAI APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ]\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_id,\n",
        "            messages=messages,\n",
        "            max_tokens=5,\n",
        "            temperature=0.4, # ëŒ€íšŒ ê·œì •ì— ë§ì¶° 0.4ë¡œ ê³ ì •\n",
        "            top_p=0.95\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except openai.APIError as e:\n",
        "        err_str = str(e).lower()\n",
        "        if \"authentication\" in err_str or \"401\" in err_str:\n",
        "            raise Exception(f\"OpenAI API ì˜¤ë¥˜: ì¸ì¦ ì‹¤íŒ¨. OpenAI API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "        if \"rate limit\" in err_str or \"429\" in err_str:\n",
        "            raise Exception(f\"OpenAI API ì˜¤ë¥˜: ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
        "        if \"not found\" in err_str or \"404\" in err_str:\n",
        "             raise Exception(f\"OpenAI API ì˜¤ë¥˜: ëª¨ë¸ '{model_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        raise Exception(f\"OpenAI API ì˜¤ë¥˜: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"OpenAI ë¡¤ì•„ì›ƒ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "\n",
        "\n",
        "def evaluation_and_feedback_function(output, task):\n",
        "    \"\"\"\n",
        "    ëª¨ë¸ì˜ ì¶œë ¥ì´ ì •í™•íˆ '0' ë˜ëŠ” '1'ì¸ì§€ ì±„ì í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    if not output or not isinstance(output, str):\n",
        "        return {\"score\": 0.0, \"feedback\": \"ì‹¤íŒ¨: ìœ íš¨í•œ ì¶œë ¥ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"}\n",
        "\n",
        "    expected_output = task.get(\"expected_output\")\n",
        "\n",
        "    if output not in [\"0\", \"1\"]:\n",
        "        return {\"score\": 0.0, \"feedback\": f\"ì‹¤íŒ¨: ì¶œë ¥ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¶œë ¥: '{output}', ì˜ˆìƒ: '{expected_output}')\"}\n",
        "\n",
        "    if output == expected_output:\n",
        "        score = 1.0\n",
        "        feedback = \"ì„±ê³µ: ì˜ˆìƒëœ ê°’ê³¼ ì •í™•íˆ ì¼ì¹˜í–ˆìŠµë‹ˆë‹¤.\"\n",
        "    else:\n",
        "        score = 0.0\n",
        "        feedback = f\"ì‹¤íŒ¨: ì˜ˆìƒ ê°’ì€ '{expected_output}'ì´ì—ˆì§€ë§Œ, ê²°ê³¼ëŠ” '{output}'ì´ì—ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    return {\"score\": score, \"feedback\": feedback}\n",
        "\n",
        "\n",
        "def reflect_and_propose_new_prompt(gemini_client, reflector_model_name, current_prompt, examples):\n",
        "    \"\"\"\n",
        "    ê°•ë ¥í•œ LLM(Gemini)ì„ ì‚¬ìš©í•˜ì—¬ 'ë°˜ì„±ì  í”„ë¡¬í”„íŠ¸ ë³€í˜•' ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. (genai.Client ì‚¬ìš©)\n",
        "    \"\"\"\n",
        "    examples_text = '---\\n'.join(\n",
        "        f'ê³¼ì œ ì…ë ¥:\\n{e[\"input\"]}\\n\\nìƒì„±ëœ ì¶œë ¥: \"{e[\"output\"]}\"\\ní”¼ë“œë°±: {e[\"feedback\"]}\\n\\n'\n",
        "        for e in examples\n",
        "    )\n",
        "\n",
        "    reflection_prompt = f\"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ì „ ì‹œë„ì—ì„œ ì–»ì€ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ gpt-4o-mini ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "    ê°œì„ ì´ í•„ìš”í•œ í˜„ì¬ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "    --- í˜„ì¬ í”„ë¡¬í”„íŠ¸ ---\n",
        "    {current_prompt}\n",
        "    --------------------\n",
        "\n",
        "    ë‹¤ìŒì€ ì´ í”„ë¡¬í”„íŠ¸ê°€ ëª‡ ê°€ì§€ ê³¼ì œì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€, ê·¸ë¦¬ê³  ë¬´ì—‡ì´ ì˜ë˜ì—ˆê³  ì˜ëª»ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ í”¼ë“œë°± ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
        "    --- ì˜ˆì‹œ ë° í”¼ë“œë°± ---\n",
        "    {examples_text}\n",
        "    -------------------------\n",
        "\n",
        "    ì´ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ìƒˆë¡­ê³  ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì´ ë‹¹ì‹ ì˜ ì„ë¬´ì…ë‹ˆë‹¤.\n",
        "    ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:\n",
        "    1. ì‹¤íŒ¨ ì›ì¸ì„ ì§ì ‘ì ìœ¼ë¡œ í•´ê²°í•˜ê³  ì„±ê³µ ì „ëµì„ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    2. í‰ê°€ì— ê¸¸ì´ ì ìˆ˜ê°€ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ ê°€ì¥ ê°„ê²°í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "    ë‹¹ì‹ ì˜ ì‘ë‹µì€ ì˜¤ì§ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ë§Œ í¬í•¨í•´ì•¼ í•˜ë©°, ê·¸ ì™¸ì˜ ë‚´ìš©ì€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # genai.Clientë¥¼ ì‚¬ìš©í•˜ì—¬ API í˜¸ì¶œ\n",
        "        response = gemini_client.models.generate_content(\n",
        "            model=reflector_model_name,\n",
        "            contents=reflection_prompt,\n",
        "            config=types.GenerateContentConfig(\n",
        "                temperature=0.2,\n",
        "                top_p=0.95,\n",
        "                top_k=30,\n",
        "                thinking_config=types.ThinkingConfig(thinking_budget=2048)\n",
        "            )\n",
        "        )\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Gemini API ì˜¤ë¥˜: {str(e)}. Gemini API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "\n",
        "def select_candidate_for_mutation(candidate_pool, num_tasks):\n",
        "    \"\"\"íŒŒë ˆí†  ê¸°ë°˜ ì „ëµì— ë”°ë¼ ë³€í˜•í•  ë‹¤ìŒ í›„ë³´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
        "    if not candidate_pool:\n",
        "        return None\n",
        "    if len(candidate_pool) == 1:\n",
        "        return candidate_pool[0]\n",
        "\n",
        "    best_scores_per_task = [-1.0] * num_tasks\n",
        "    for candidate in candidate_pool:\n",
        "        for i in range(num_tasks):\n",
        "            if candidate[\"scores\"][i] > best_scores_per_task[i]:\n",
        "                best_scores_per_task[i] = candidate[\"scores\"][i]\n",
        "\n",
        "    pareto_front_ids = {\n",
        "        c[\"id\"]\n",
        "        for c in candidate_pool\n",
        "        for i in range(num_tasks)\n",
        "        if abs(c[\"scores\"][i] - best_scores_per_task[i]) < 1e-6\n",
        "    }\n",
        "\n",
        "    if not pareto_front_ids:\n",
        "        return max(candidate_pool, key=lambda c: c[\"avg_score\"])\n",
        "\n",
        "    selected_id = random.choice(list(pareto_front_ids))\n",
        "    return next(c for c in candidate_pool if c[\"id\"] == selected_id)\n",
        "\n",
        "\n",
        "def test_model_connection(client, model_id):\n",
        "    \"\"\"ëª¨ë¸ì— ì ‘ê·¼ ê°€ëŠ¥í•˜ê³  ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\"\"\"\n",
        "    try:\n",
        "        response = run_openai_rollout(client, model_id, \"Say hello\", \"Hello, world!\")\n",
        "        return True, response\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "\n",
        "def run_gepa_optimization(openai_key, gemini_key, model_id, reflector_model_name, seed_prompt, training_data, budget):\n",
        "    \"\"\"\n",
        "    GEPA ìµœì í™” í”„ë¡œì„¸ìŠ¤ë¥¼ ì´ê´„í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜.\n",
        "    \"\"\"\n",
        "    # --- ì´ˆê¸°í™” ---\n",
        "    print(log_message(\"GEPA ìµœì í™” í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\"))\n",
        "    openai_client = openai.OpenAI(api_key=openai_key)\n",
        "    # google.generativeai.Client ì´ˆê¸°í™”\n",
        "    gemini_client = genai.Client(api_key=gemini_key)\n",
        "\n",
        "    rollout_count = 0\n",
        "    candidate_pool = []\n",
        "    best_candidate = {\"prompt\": \"ì´ˆê¸°í™” ì¤‘...\", \"avg_score\": -1.0}\n",
        "\n",
        "    # --- ëª¨ë¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ---\n",
        "    print(log_message(f\"ëŒ€ìƒ ëª¨ë¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘: {model_id}\"))\n",
        "    connection_ok, test_result = test_model_connection(openai_client, model_id)\n",
        "    if not connection_ok:\n",
        "        print(log_message(f\"ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: {test_result}\", 'fail'))\n",
        "        raise Exception(f\"ëª¨ë¸ '{model_id}'ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_result}\")\n",
        "    print(log_message(\"ëª¨ë¸ ì—°ê²° ì„±ê³µ!\", 'success'))\n",
        "\n",
        "    # --- ì´ˆê¸° ì‹œë“œ í”„ë¡¬í”„íŠ¸ í‰ê°€ ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(log_message(\"1ë‹¨ê³„: ì´ˆê¸° ì‹œë“œ í”„ë¡¬í”„íŠ¸ í‰ê°€\"))\n",
        "    initial_candidate = {\"id\": 0, \"prompt\": seed_prompt, \"parentId\": None, \"scores\": [0.0] * len(training_data), \"avg_score\": 0.0}\n",
        "    total_score = 0.0\n",
        "    for i, task in enumerate(training_data):\n",
        "        print(log_message(f\"  - ì‹œë“œ í‰ê°€ ì¤‘ ({i+1}/{len(training_data)} ë²ˆì§¸ ì‘ì—…)...\"))\n",
        "        try:\n",
        "            output = run_openai_rollout(openai_client, model_id, initial_candidate[\"prompt\"], task[\"input\"])\n",
        "            eval_result = evaluation_and_feedback_function(output, task)\n",
        "            initial_candidate[\"scores\"][i] = eval_result[\"score\"]\n",
        "            total_score += eval_result[\"score\"]\n",
        "        except Exception as e:\n",
        "            print(log_message(f\"ì‘ì—… {i+1}ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", 'fail'))\n",
        "            initial_candidate[\"scores\"][i] = 0.0\n",
        "        finally:\n",
        "            rollout_count += 1\n",
        "\n",
        "    initial_candidate[\"avg_score\"] = total_score / len(training_data) if training_data else 0.0\n",
        "    candidate_pool.append(initial_candidate)\n",
        "    best_candidate = initial_candidate\n",
        "\n",
        "    print(log_message(f\"ì‹œë“œ í”„ë¡¬í”„íŠ¸ ì´ˆê¸° ì ìˆ˜: {initial_candidate['avg_score']:.2f}\", 'best'))\n",
        "    print(f\"í˜„ì¬ ìµœì ì˜ í”„ë¡¬í”„íŠ¸:\\n---\\n{best_candidate['prompt']}\\n---\")\n",
        "\n",
        "    # --- ë©”ì¸ ìµœì í™” ë£¨í”„ ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(log_message(f\"2ë‹¨ê³„: ìµœì í™” ë£¨í”„ ì‹œì‘ (ì˜ˆì‚°: {budget} ë¡¤ì•„ì›ƒ)\"))\n",
        "    while rollout_count < budget:\n",
        "        print(log_message(f\"--- ë°˜ë³µ ì‹œì‘ (ë¡¤ì•„ì›ƒ: {rollout_count}/{budget}) ---\"))\n",
        "\n",
        "        parent_candidate = select_candidate_for_mutation(candidate_pool, len(training_data))\n",
        "        print(log_message(f\"í›„ë³´ #{parent_candidate['id']} (ì ìˆ˜: {parent_candidate['avg_score']:.2f})ë¥¼ ë³€í˜• ëŒ€ìƒìœ¼ë¡œ ì„ íƒí–ˆìŠµë‹ˆë‹¤.\"))\n",
        "\n",
        "        task_index = random.randint(0, len(training_data) - 1)\n",
        "        reflection_task = training_data[task_index]\n",
        "        print(log_message(f\"ì‘ì—… {task_index + 1}ì„ ì‚¬ìš©í•˜ì—¬ ë°˜ì„±ì  ë³€í˜•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...\"))\n",
        "\n",
        "        try:\n",
        "            rollout_output = run_openai_rollout(openai_client, model_id, parent_candidate[\"prompt\"], reflection_task[\"input\"])\n",
        "            rollout_count += 1\n",
        "            eval_result = evaluation_and_feedback_function(rollout_output, reflection_task)\n",
        "\n",
        "            new_prompt = reflect_and_propose_new_prompt(gemini_client, reflector_model_name, parent_candidate[\"prompt\"], [{\n",
        "                \"input\": reflection_task[\"input\"], \"output\": rollout_output, \"feedback\": eval_result[\"feedback\"]\n",
        "            }])\n",
        "\n",
        "            new_candidate = {\"id\": len(candidate_pool), \"prompt\": new_prompt, \"parentId\": parent_candidate[\"id\"], \"scores\": [0.0] * len(training_data), \"avg_score\": 0.0}\n",
        "            print(log_message(f\"ìƒˆë¡œìš´ í›„ë³´ í”„ë¡¬í”„íŠ¸ #{new_candidate['id']}ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\"))\n",
        "\n",
        "            new_total_score = 0.0\n",
        "            for i, task in enumerate(training_data):\n",
        "                if rollout_count >= budget:\n",
        "                    print(log_message(\"ìƒˆ í›„ë³´ í‰ê°€ ì¤‘ ì˜ˆì‚°ì„ ëª¨ë‘ ì†Œì§„í–ˆìŠµë‹ˆë‹¤.\", 'fail'))\n",
        "                    break\n",
        "                try:\n",
        "                    output = run_openai_rollout(openai_client, model_id, new_candidate[\"prompt\"], task[\"input\"])\n",
        "                    eval_result = evaluation_and_feedback_function(output, task)\n",
        "                    new_candidate[\"scores\"][i] = eval_result[\"score\"]\n",
        "                    new_total_score += eval_result[\"score\"]\n",
        "                except Exception as e:\n",
        "                    print(log_message(f\"ìƒˆ í›„ë³´ë¥¼ ì‘ì—… {i+1}ì—ì„œ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", 'fail'))\n",
        "                    new_candidate[\"scores\"][i] = 0.0\n",
        "                finally:\n",
        "                    rollout_count += 1\n",
        "\n",
        "            new_candidate[\"avg_score\"] = new_total_score / len(training_data) if training_data else 0.0\n",
        "\n",
        "            if new_candidate[\"avg_score\"] >= best_candidate[\"avg_score\"]:\n",
        "                print(log_message(f\"ìƒˆ í›„ë³´ #{new_candidate['id']} ì„±ëŠ¥ í–¥ìƒ ë˜ëŠ” ìœ ì§€! ì ìˆ˜: {new_candidate['avg_score']:.2f} >= {best_candidate['avg_score']:.2f}\", 'success'))\n",
        "                candidate_pool.append(new_candidate)\n",
        "                if new_candidate[\"avg_score\"] > best_candidate[\"avg_score\"]:\n",
        "                    best_candidate = new_candidate\n",
        "                    print(log_message(\"ìƒˆë¡œìš´ ìµœì ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!\", 'best'))\n",
        "                    print(f\"í˜„ì¬ ìµœì ì˜ í”„ë¡¬í”„íŠ¸:\\n---\\n{best_candidate['prompt']}\\n---\")\n",
        "            else:\n",
        "                print(log_message(f\"ìƒˆ í›„ë³´ #{new_candidate['id']}ëŠ” ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ìˆ˜: {new_candidate['avg_score']:.2f}. íê¸°í•©ë‹ˆë‹¤.\", 'fail'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(log_message(f\"ìµœì í™” ë°˜ë³µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", 'fail'))\n",
        "            rollout_count += 1\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(log_message(\"ìµœì í™” ì˜ˆì‚°ì„ ëª¨ë‘ ì†Œì§„í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.\", 'best'))\n",
        "    print(f\"ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ (ì ìˆ˜: {best_candidate['avg_score']:.2f}):\")\n",
        "    print(f\"\\n{best_candidate['prompt']}\\n\")\n",
        "    print(\"=\"*50)\n",
        "    return best_candidate\n",
        "\n",
        "# ==============================================================================\n",
        "#                                ë©”ì¸ ì‹¤í–‰ ë¸”ë¡\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # --- 2. ì„¤ì • ---\n",
        "    # ì—¬ê¸°ì— ìµœì í™” ì‹¤í–‰ì„ ìœ„í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n",
        "\n",
        "    # --- API í‚¤ (Colab Secretsì—ì„œ ë¡œë“œ) ---\n",
        "    try:\n",
        "        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')    \n",
        "        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "    except Exception as e:\n",
        "        print(\"Colab Secretsì—ì„œ API í‚¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'OPENAI_API_KEY'ì™€ 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "        OPENAI_API_KEY, GEMINI_API_KEY = None, None\n",
        "\n",
        "    # --- ëª¨ë¸ ì„¤ì • ---\n",
        "    MODEL_ID = \"gpt-4o-mini\"\n",
        "    REFLECTOR_MODEL_NAME = \"gemini-2.5-pro\"\n",
        "\n",
        "    # --- ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ì„¤ì • ---\n",
        "    SEED_PROMPT = \"\"\"ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œì‹œëœ ê¸°ì‚¬ê°€ ìë™ì°¨ ì‚°ì—…ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì—¬ ìˆ«ìë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.\n",
        "\n",
        "ã€íŒë‹¨ ê¸°ì¤€ã€‘\n",
        "ìë™ì°¨ ê´€ë ¨(1)ìœ¼ë¡œ ë¶„ë¥˜:\n",
        "- ìë™ì°¨ ì œì¡°ì‚¬ê°€ ì£¼ìš” ì£¼ì²´ì¸ ê¸°ì‚¬\n",
        "- ìë™ì°¨/ì „ê¸°ì°¨/ìˆ˜ì†Œì°¨ì˜ ìƒì‚°, íŒë§¤, ê°œë°œ ë‚´ìš©\n",
        "- ìë™ì°¨ ì „ìš© ë¶€í’ˆ/ê¸°ìˆ : ë°°í„°ë¦¬(ì „ê¸°ì°¨ìš©), ë°˜ë„ì²´(ì°¨ëŸ‰ìš©), íƒ€ì´ì–´, ìœ ë¦¬, íŒŒì›ŒíŠ¸ë ˆì¸, ì—´ê´€ë¦¬ì‹œìŠ¤í…œ, ì¹´ë©”ë¼ëª¨ë“ˆ(ì°¨ëŸ‰ìš©), APëª¨ë“ˆ(ì°¨ëŸ‰ìš©), EVCC\n",
        "- ìë™ì°¨ ì§ì ‘ ì„œë¹„ìŠ¤: ì¶©ì „ì†Œ, ì •ë¹„, ìë™ì°¨ë³´í—˜, ì¹´ì…°ì–´ë§\n",
        "- ììœ¨ì£¼í–‰ ê¸°ìˆ (ì°¨ëŸ‰ ì ìš© ëª…ì‹œ)\n",
        "- ëª¨ë¹Œë¦¬í‹° ì„œë¹„ìŠ¤(UAM í¬í•¨)\n",
        "\n",
        "ìë™ì°¨ ë¬´ê´€(0)ìœ¼ë¡œ ë¶„ë¥˜:\n",
        "- ìë™ì°¨ê°€ ë‹¨ìˆœ ì˜ˆì‹œë¡œë§Œ ì–¸ê¸‰\n",
        "- ë²”ìš© ê¸°ìˆ /ë¶€í’ˆ(ìë™ì°¨ íŠ¹ì • ì–¸ê¸‰ ì—†ìŒ): ì¼ë°˜ ë°˜ë„ì²´, ì¼ë°˜ ë°°í„°ë¦¬, ì¼ë°˜ AI/ë¡œë´‡\n",
        "- ì—ë„ˆì§€/ESS(ì£¼íƒìš©/ì‚°ì—…ìš©)\n",
        "- ë¬´ì—­ì •ì±…/ê´€ì„¸(ìë™ì°¨ íŠ¹ì • ì–¸ê¸‰ ì—†ìŒ)\n",
        "- íƒ€ ì‚°ì—… ì¤‘ì‹¬(ë°©ì‚°, í•­ê³µ, ì² ë„ ë“±)\n",
        "\n",
        "ã€í•µì‹¬ ì‹ë³„ íŒ¨í„´ã€‘\n",
        "âœ“ ê¸°ì—…ëª…+ìë™ì°¨ ì‚¬ì—…: í˜„ëŒ€ì°¨, ê¸°ì•„, GM, í…ŒìŠ¬ë¼, BYD, ë„ìš”íƒ€ ë“±\n",
        "âœ“ ìë™ì°¨ ì „ìš© í‚¤ì›Œë“œ: ì „ê¸°ì°¨, EV, ììœ¨ì£¼í–‰ì°¨, ADAS, SDV, ì¶©ì „ì¸í”„ë¼, OEM(ìë™ì°¨)\n",
        "âœ“ ë¶€í’ˆì‚¬+ìë™ì°¨ ê³µê¸‰: \"ì°¨ëŸ‰ìš©\", \"ìë™ì°¨ìš©\", \"ì „ê¸°ì°¨ìš©\", \"ìë™ì°¨ OEM ê³µê¸‰\"\n",
        "\n",
        "ã€ê²½ê³„ ì‚¬ë¡€ íŒë‹¨ã€‘\n",
        "- ë°°í„°ë¦¬ â†’ ì „ê¸°ì°¨ìš© ëª…ì‹œ(1) / ESSÂ·ì£¼íƒìš©(0)\n",
        "- ë°˜ë„ì²´ â†’ ì°¨ëŸ‰ìš©Â·ììœ¨ì£¼í–‰ìš©(1) / ì¼ë°˜Â·ë°ì´í„°ì„¼í„°ìš©(0)\n",
        "- AI/ë¡œë´‡ â†’ ììœ¨ì£¼í–‰Â·ì°¨ë‚´ ì‹œìŠ¤í…œ(1) / ì‚°ì—…ìš©Â·ì¼ë°˜(0)\n",
        "- ì¸í”„ë¼ â†’ ì¶©ì „ì†ŒÂ·ììœ¨ì£¼í–‰ë„ë¡œ(1) / ì¼ë°˜ ìŠ¤ë§ˆíŠ¸ì‹œí‹°(0)\n",
        "- M&A/íˆ¬ì â†’ ìë™ì°¨ ê¸°ì—…Â·ë¶€í’ˆì‚¬(1) / íƒ€ì—…ì¢…(0)\n",
        "\n",
        "ã€ì¤‘ìš”ã€‘\n",
        "- ì œëª©ê³¼ ë³¸ë¬¸ ì „ì²´ë¥¼ ì¢…í•© íŒë‹¨\n",
        "- ìë™ì°¨ê°€ í•µì‹¬ ì£¼ì œì¸ì§€ í™•ì¸\n",
        "- ì• ë§¤í•œ ê²½ìš° ë³¸ë¬¸ì˜ ì£¼ìš” ë…¼ì  ê¸°ì¤€\n",
        "- ë°˜ë“œì‹œ 0 ë˜ëŠ” 1ë§Œ ì¶œë ¥\n",
        "- ì„¤ëª…ì´ë‚˜ ì´ìœ  ì—†ì´ ìˆ«ìë§Œ ì‘ë‹µ\n",
        "\n",
        "ì¶œë ¥: 0 ë˜ëŠ” 1\"\"\"\n",
        "\n",
        "    # --- í›ˆë ¨ ë°ì´í„° ì„¤ì • (CSV íŒŒì¼ë¡œë¶€í„° ë¡œë“œ) ---\n",
        "    TRAINING_DATA = []\n",
        "    try:\n",
        "        # Colabì— ì—…ë¡œë“œëœ CSV íŒŒì¼ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”.\n",
        "        df = pd.read_csv('./data/car_samples.csv')\n",
        "        for index, row in df.iterrows():\n",
        "            # ëŒ€íšŒ ìœ ì € í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ì¶° input ë°ì´í„° êµ¬ì„±\n",
        "            input_text = f\"[ê¸°ì‚¬]\\n\\nì œëª©: {row['title']}\\n\\në‚´ìš©: {row['content']}\"\n",
        "            TRAINING_DATA.append({\n",
        "                \"input\": input_text,\n",
        "                \"expected_output\": str(row['label'])\n",
        "            })\n",
        "        print(log_message(f\"'{df.shape[0]}'ê°œì˜ í›ˆë ¨ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œë¶€í„° ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\", 'success'))\n",
        "    except FileNotFoundError:\n",
        "        print(log_message(\"CSV íŒŒì¼('car_samples.csv')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Colabì— íŒŒì¼ì„ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\", 'fail'))\n",
        "        TRAINING_DATA = None # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‹¤í–‰ ì¤‘ë‹¨\n",
        "    except Exception as e:\n",
        "        print(log_message(f\"CSV íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\", 'fail'))\n",
        "        TRAINING_DATA = None\n",
        "\n",
        "    # --- ì˜ˆì‚° ì„¤ì • ---\n",
        "    BUDGET = 50 # í›ˆë ¨ ë°ì´í„°ê°€ ë§ì•„ì¡Œìœ¼ë¯€ë¡œ ì˜ˆì‚°ì„ ëŠ˜ë¦¬ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
        "\n",
        "    # --- 3. ìµœì í™” ì‹¤í–‰ ---\n",
        "    if OPENAI_API_KEY and GEMINI_API_KEY and TRAINING_DATA:\n",
        "      try:\n",
        "          final_result = run_gepa_optimization(\n",
        "              openai_key=OPENAI_API_KEY,\n",
        "              gemini_key=GEMINI_API_KEY,\n",
        "              model_id=MODEL_ID,\n",
        "              reflector_model_name=REFLECTOR_MODEL_NAME,\n",
        "              seed_prompt=SEED_PROMPT,\n",
        "              training_data=TRAINING_DATA,\n",
        "              budget=BUDGET\n",
        "          )\n",
        "      except Exception as e:\n",
        "          print(f\"\\nì‹¤í–‰ ì¤‘ ë³µêµ¬í•  ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dacon-kt-prompt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
